{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import attr\n",
    "import functools\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from math import sqrt \n",
    "import numpy as np \n",
    "import scipy.misc \n",
    "from IPython.display import display \n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization,Activation,Average\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.regularizers import l1, l2\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_n = pd.read_csv(\"out.csv\")\n",
    "df_o = pd.read_csv(\"new.csv\")\n",
    "data = pd.read_csv(\"dataset.csv\")\n",
    "data = data.iloc[:,1:]\n",
    "\n",
    "emotion = df_o.iloc[:,4]\n",
    "df = pd.concat([data, emotion], ignore_index=True, axis=1)\n",
    "\n",
    "TRAIN_DATA_PER_CLIENT = 50\n",
    "\n",
    "TRAINING_EPOCHS = 3\n",
    "\n",
    "\n",
    "x_client_1 = data[0 : TRAIN_DATA_PER_CLIENT]\n",
    "y_client_1 = emotion[0 : TRAIN_DATA_PER_CLIENT]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<BatchDataset shapes: OrderedDict([(x, (None, 9)), (y, (None,))]), types: OrderedDict([(x, tf.float64), (y, tf.int64)])>"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "\n",
    "from tensorflow import reshape\n",
    "from collections import OrderedDict\n",
    "\n",
    "def create_federated_data(x_train, y_train):\n",
    "\n",
    "    orderDict = OrderedDict()\n",
    "\n",
    "    orderDict['x'] = np.array(x_train)\n",
    "    orderDict['y'] = np.array(y_train)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(orderDict)\n",
    "    batch = dataset.shuffle(10).batch(5)\n",
    "\n",
    "    return batch\n",
    "\n",
    "federated_data_client_1 = [create_federated_data(x_client_1, y_client_1) for epoch in range(TRAINING_EPOCHS)]\n",
    "\n",
    "federated_data_client_1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "\n",
    "\n",
    "def create_model_lite():\n",
    "    input_shape=(48,48,1)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(6, (5, 5), input_shape=input_shape, padding='same', activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(16, (5, 5), padding='same', activation = 'relu'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation = 'relu'))\n",
    "    \n",
    "    \n",
    "    \n",
    "    return model\n",
    "\n",
    "def baseline_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(64,input_shape=(9,), activation='relu'))\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 48, 48, 6)         156       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 24, 24, 6)         0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 24, 24, 16)        2416      \n_________________________________________________________________\nactivation (Activation)      (None, 24, 24, 16)        0         \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 12, 12, 16)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 10, 10, 64)        9280      \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n_________________________________________________________________\nflatten (Flatten)            (None, 1600)              0         \n_________________________________________________________________\ndense (Dense)                (None, 64)                102464    \n=================================================================\nTotal params: 114,316\nTrainable params: 114,316\nNon-trainable params: 0\n_________________________________________________________________\nNone\nModel: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_1 (Dense)              (None, 64)                640       \n=================================================================\nTotal params: 640\nTrainable params: 640\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
     ]
    }
   ],
   "source": [
    "model1 = create_model_lite()\n",
    "print(model1.summary())\n",
    "model2 = baseline_model()\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 48, 48, 1), dtype=tf.float32, name='conv2d_input'), name='conv2d_input', description=\"created by layer 'conv2d_input'\") KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='dense_1_input'), name='dense_1_input', description=\"created by layer 'dense_1_input'\")\nModel: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nconv2d_input (InputLayer)       [(None, 48, 48, 1)]  0                                            \n__________________________________________________________________________________________________\nconv2d (Conv2D)                 (None, 48, 48, 6)    156         conv2d_input[0][0]               \n__________________________________________________________________________________________________\nmax_pooling2d (MaxPooling2D)    (None, 24, 24, 6)    0           conv2d[0][0]                     \n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 24, 24, 16)   2416        max_pooling2d[0][0]              \n__________________________________________________________________________________________________\nactivation (Activation)         (None, 24, 24, 16)   0           conv2d_1[0][0]                   \n__________________________________________________________________________________________________\nmax_pooling2d_1 (MaxPooling2D)  (None, 12, 12, 16)   0           activation[0][0]                 \n__________________________________________________________________________________________________\nconv2d_2 (Conv2D)               (None, 10, 10, 64)   9280        max_pooling2d_1[0][0]            \n__________________________________________________________________________________________________\nmax_pooling2d_2 (MaxPooling2D)  (None, 5, 5, 64)     0           conv2d_2[0][0]                   \n__________________________________________________________________________________________________\nflatten (Flatten)               (None, 1600)         0           max_pooling2d_2[0][0]            \n__________________________________________________________________________________________________\ndense_1_input (InputLayer)      [(None, 9)]          0                                            \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 64)           102464      flatten[0][0]                    \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 64)           640         dense_1_input[0][0]              \n__________________________________________________________________________________________________\nadd (Add)                       (None, 64)           0           dense[0][0]                      \n                                                                 dense_1[0][0]                    \n__________________________________________________________________________________________________\nsequential_2 (Sequential)       (None, 7)            9223        add[0][0]                        \n==================================================================================================\nTotal params: 124,179\nTrainable params: 124,179\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import add\n",
    "merged_output = add([model1.output, model2.output])   \n",
    "model_combined = Sequential()\n",
    "model_combined.add(Activation('relu'))\n",
    "model_combined.add(Dense(128))\n",
    "model_combined.add(Activation('relu'))\n",
    "model_combined.add(Dense(7, activation='softmax'))\n",
    "\n",
    "print(model1.input,model2.input)\n",
    "\n",
    "final_model = Model([model1.input, model2.input], model_combined(merged_output))\n",
    "\n",
    "# final_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(final_model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy_batch = tf.nest.map_structure(lambda x: x.numpy(), iter(federated_data_client_1[0]).next())\n",
    "# print(dummy_batch['x'].shape)\n",
    "\n",
    "def model_fn():\n",
    "  keras_model = baseline_model()\n",
    "  return tff.learning.from_keras_model(\n",
    "      keras_model,\n",
    "      input_spec=federated_data_client_1[0].element_spec,\n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow_federated.python.learning.model_utils.EnhancedModel at 0x7fc82d371100>"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "model = model_fn()\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.weights.trainable\n",
    "\n",
    "# A server-to-client broadcast step. \n",
    "\n",
    "# A local client update step. \n",
    "\n",
    "# A client-to-server upload step. \n",
    "\n",
    "# A server update step. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'( -> <model=<trainable=<float32[9,64],float32[64]>,non_trainable=<>>,optimizer_state=<int64>,delta_aggregate_state=<value_sum_process=<>,weight_sum_process=<>>,model_broadcast_state=<>>@SERVER)'"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "iterative_process = tff.learning.build_federated_averaging_process(\n",
    "    model_fn,\n",
    "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02))\n",
    "\n",
    "str(iterative_process.initialize.type_signature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From /home/keerthi/anaconda3/lib/python3.8/site-packages/tensorflow_federated/python/core/impl/compiler/tensorflow_computation_transformations.py:58: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "WARNING:tensorflow:From /home/keerthi/anaconda3/lib/python3.8/site-packages/tensorflow_federated/python/core/impl/compiler/tensorflow_computation_transformations.py:58: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
     ]
    }
   ],
   "source": [
    "state = iterative_process.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "round  1, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('sparse_categorical_accuracy', 0.006666667), ('loss', 12.999751)])), ('stat', OrderedDict([('num_examples', 150)]))])\n"
     ]
    }
   ],
   "source": [
    "state, metrics = iterative_process.next(state, federated_data_client_1)\n",
    "print('round  1, metrics={}'.format(metrics))"
   ]
  }
 ]
}